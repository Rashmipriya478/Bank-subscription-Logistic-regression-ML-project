{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression\n",
        "#The classification goal is to predict whether the client will subscribe (1/0) to a term deposit (so this is our variable y)."
      ],
      "metadata": {
        "id": "T33IhXhZYm4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cleaning Dataframe and Manipulating"
      ],
      "metadata": {
        "id": "oouZczznZsAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "ylxzw0i2Y3Vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc(\"font\", size=14)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "sns.set(style=\"white\")\n",
        "sns.set(style=\"whitegrid\", color_codes=True)\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore')"
      ],
      "metadata": {
        "id": "Yk_Yt5tjYvxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/archive (9).csv\", header=0)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "D8XX_IFFZU1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['education'].unique()"
      ],
      "metadata": {
        "id": "CHIQvgeqZk49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.copy()"
      ],
      "metadata": {
        "id": "Hk_XIiIyZ0ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The education column of the dataset has many categories and we need to reduce the categories for a better modelling.\n",
        "#Group all the basic educations together\n",
        "data['education']=np.where(data['education'] =='basic.9y', 'Basic', data['education'])\n",
        "data['education']=np.where(data['education'] =='basic.6y', 'Basic', data['education'])\n",
        "data['education']=np.where(data['education'] =='basic.4y', 'Basic', data['education'])"
      ],
      "metadata": {
        "id": "p_3N5QmcZ3SL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Exploration"
      ],
      "metadata": {
        "id": "3h0eHqkdZ-B5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['y'].value_counts()"
      ],
      "metadata": {
        "id": "y5brZWO6aA7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_no_sub = len(data[data['y']==0])\n",
        "count_sub = len(data[data['y']==1])\n",
        "\n",
        "pct_of_no_sub = count_no_sub/(count_no_sub+count_sub)\n",
        "print(\"percentage of no subscription is\", pct_of_no_sub*100)\n",
        "\n",
        "pct_of_sub = count_sub/(count_no_sub+count_sub)\n",
        "print(\"percentage of subscription\", pct_of_sub*100)"
      ],
      "metadata": {
        "id": "R_VSXsjnaEGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the numeric columns from the DataFrame\n",
        "numeric_data = data.select_dtypes(include=['number'])\n",
        "\n",
        "# Group by 'y' and calculate the mean for numeric columns only\n",
        "grouped_mean = numeric_data.groupby(data['y']).mean()\n",
        "\n",
        "print(grouped_mean)\n"
      ],
      "metadata": {
        "id": "mNk9chx8cpQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the value counts for the 'y' column\n",
        "y_value_counts = data['y'].value_counts()\n",
        "print(y_value_counts)\n",
        "\n",
        "# Select only the numeric columns from the DataFrame\n",
        "numeric_cols = data.select_dtypes(include=['number'])\n",
        "\n",
        "# Group by 'y' and calculate the mean for numeric columns only\n",
        "grouped_mean = data.groupby('y')[numeric_cols.columns].mean()\n",
        "\n",
        "print(grouped_mean)\n"
      ],
      "metadata": {
        "id": "HH5wnxawcV_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the numeric columns from the DataFrame\n",
        "numeric_cols = data.select_dtypes(include=['number'])\n",
        "\n",
        "# Group by 'marital' and calculate the mean for numeric columns only\n",
        "grouped_mean = data.groupby('marital')[numeric_cols.columns].mean()\n",
        "\n",
        "# Display the result\n",
        "print(grouped_mean)\n"
      ],
      "metadata": {
        "id": "TPcqa8rHdBtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualization"
      ],
      "metadata": {
        "id": "yg5hEwdydfuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "pd.crosstab(data.job,data.y).plot(kind='bar')\n",
        "plt.title('Purchase Frequency for Job Title')\n",
        "plt.xlabel('Job')\n",
        "plt.ylabel('Frequency of Purchase')\n",
        "plt.savefig('purchase_fre_job')"
      ],
      "metadata": {
        "id": "q-CcJ0hPdhZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table=pd.crosstab(data.marital,data.y)\n",
        "table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
        "plt.title('Stacked Bar Chart of Marital Status vs Purchase')\n",
        "plt.xlabel('Marital Status')\n",
        "plt.ylabel('Proportion of Customers')\n",
        "plt.savefig('mariral_vs_pur_stack')"
      ],
      "metadata": {
        "id": "-ciRcqhPdqXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Marital status doesn't seem to be a good predictor"
      ],
      "metadata": {
        "id": "QIenC5Wkdtvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table=pd.crosstab(data.education,data.y)\n",
        "table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
        "plt.title('Stacked Bar Chart of Education vs Purchase')\n",
        "plt.xlabel('Education')\n",
        "plt.ylabel('Proportion of Customers')\n",
        "plt.savefig('edu_vs_pur_stack')"
      ],
      "metadata": {
        "id": "B6kk4-xIdv-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(data.month,data.y).plot(kind='bar')\n",
        "plt.title('Purchase Frequency for Month')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Frequency of Purchase')\n",
        "plt.savefig('pur_fre_month_bar')"
      ],
      "metadata": {
        "id": "9Ua9ZrGodzBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.age.hist()\n",
        "plt.title('Histogram of Age')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.savefig('hist_age')"
      ],
      "metadata": {
        "id": "Xf7Ax-Med3E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(data.poutcome,data.y).plot(kind='bar')\n",
        "plt.title('Purchase Frequency for Poutcome')\n",
        "plt.xlabel('Poutcome')\n",
        "plt.ylabel('Frequency of Purchase')\n",
        "plt.savefig('pur_fre_pout_bar')"
      ],
      "metadata": {
        "id": "P05B5VT_d7Zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#One Hot Encoding"
      ],
      "metadata": {
        "id": "4VFDehBYeAj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
        "for var in cat_vars:\n",
        "    cat_list='var'+'_'+var\n",
        "    cat_list = pd.get_dummies(data[var], prefix=var)\n",
        "    data1=data.join(cat_list)\n",
        "    data=data1\n",
        "cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
        "data_vars=data.columns.values.tolist()\n",
        "to_keep=[i for i in data_vars if i not in cat_vars]\n",
        "\n",
        "data_final=data[to_keep]\n",
        "data_final.columns.values"
      ],
      "metadata": {
        "id": "nO6T0FYoeDkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression & Results"
      ],
      "metadata": {
        "id": "IZIVBZ2DeIom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_final.loc[:, data_final.columns != 'y']\n",
        "y = data_final.loc[:, data_final.columns == 'y']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "emqurnvdeL-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "os = SMOTE(random_state = 0)"
      ],
      "metadata": {
        "id": "nTTBWfmweOzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Initialize the SMOTE object\n",
        "os = SMOTE(random_state=42)\n",
        "\n",
        "# Resample the training data\n",
        "os_data_X, os_data_y = os.fit_resample(X_train, y_train)\n",
        "\n",
        "# Convert the resampled data to DataFrames\n",
        "columns = X_train.columns\n",
        "os_data_X = pd.DataFrame(data=os_data_X, columns=columns)\n",
        "os_data_y = pd.DataFrame(data=os_data_y, columns=['y'])\n"
      ],
      "metadata": {
        "id": "-XlGLyKNenSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of oversampled data is \",len(os_data_X))\n",
        "print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
        "print(\"Number of subscription\",len(os_data_y[os_data_y['y']==1]))"
      ],
      "metadata": {
        "id": "Nvg13C2feToU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use liblinear solver for faster performance\n",
        "model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "\n",
        "# Use 5-fold cross-validation instead of 10\n",
        "rfecv = RFECV(estimator=model, step=1, cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "\n",
        "# Fit the model\n",
        "rfecv.fit(os_data_X, os_data_y.values.ravel())\n",
        "\n",
        "# Output the results\n",
        "print(\"Optimal number of features: %d\" % rfecv.n_features_)\n",
        "print('Selected features: %s' % list(os_data_X.columns[rfecv.support_]))\n",
        "\n",
        "# Plot the number of features vs. cross-validation scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross-validation score (AUC)\")\n",
        "\n",
        "# Use `mean_test_score` from `cv_results_`\n",
        "plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), rfecv.cv_results_['mean_test_score'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qq_zbHC9iVev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RFE has helped us choose the following columns\n",
        "selected_features = ['emp_var_rate', 'cons_price_idx', 'job_admin.', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'job_unknown', 'marital_divorced', 'marital_married', 'marital_single', 'marital_unknown', 'education_Basic', 'education_high.school', 'education_professional.course', 'education_university.degree', 'education_unknown', 'default_no', 'default_unknown', 'housing_no', 'housing_unknown', 'housing_yes', 'loan_no', 'loan_unknown', 'loan_yes', 'contact_cellular', 'contact_telephone', 'month_apr', 'month_aug', 'month_dec', 'month_jul', 'month_jun', 'month_may', 'month_nov', 'month_oct', 'month_sep', 'day_of_week_fri', 'day_of_week_mon', 'day_of_week_thu', 'day_of_week_tue', 'day_of_week_wed', 'poutcome_failure', 'poutcome_nonexistent']"
      ],
      "metadata": {
        "id": "5J67pdxLBhZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os_data_X.columns)\n",
        "print(X_test.columns)\n"
      ],
      "metadata": {
        "id": "g8k0TJaaCunt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = [feature for feature in selected_features if feature in os_data_X.columns and feature in X_test.columns]\n",
        "os_data_X = os_data_X[selected_features]\n",
        "X_test = X_test[selected_features]\n"
      ],
      "metadata": {
        "id": "JnKl3RtUCy8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check classification scores of logistic regression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(os_data_X, os_data_y)\n",
        "y_pred = logreg.predict(X_test)\n",
        "y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
        "[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "print('Train/Test split results:')\n",
        "print(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_pred))\n",
        "print(logreg.__class__.__name__+\" log_loss is %2.3f\" % log_loss(y_test, y_pred_proba))\n",
        "print(logreg.__class__.__name__+\" auc is %2.3f\" % auc(fpr, tpr))\n",
        "\n",
        "idx = np.min(np.where(tpr > 0.95)) # index of the first threshold for which the sensibility > 0.95\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='coral', label='ROC curve (area = %0.3f)' % auc(fpr, tpr))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot([0,fpr[idx]], [tpr[idx],tpr[idx]], 'k--', color='blue')\n",
        "plt.plot([fpr[idx],fpr[idx]], [0,tpr[idx]], 'k--', color='blue')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\n",
        "plt.ylabel('True Positive Rate (recall)', fontsize=14)\n",
        "plt.title('Receiver operating characteristic (ROC) curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Using a threshold of %.3f \" % thr[idx] + \"guarantees a sensitivity of %.3f \" % tpr[idx] +\n",
        "      \"and a specificity of %.3f\" % (1-fpr[idx]) +\n",
        "      \", i.e. a false positive rate of %.2f%%.\" % (np.array(fpr[idx])*100))"
      ],
      "metadata": {
        "id": "rPHEbdLsCbn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "SLgo7kKbDBtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "UV6Ws2BvDGdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#K-fold cross-validation"
      ],
      "metadata": {
        "id": "vOYS4vc7DK94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10-fold cross-validation logistic regression\n",
        "logreg = LogisticRegression()\n",
        "# Use cross_val_score function\n",
        "# We are passing the entirety of X and y since cross validation takes care of splitting the data\n",
        "# cv=10 for 10 folds\n",
        "# scoring = {'accuracy', 'neg_log_loss', 'roc_auc'} for evaluation metric - althought they are many\n",
        "scores_accuracy = cross_val_score(logreg, X, y, cv=10, scoring='accuracy')\n",
        "scores_log_loss = cross_val_score(logreg, X, y, cv=10, scoring='neg_log_loss')\n",
        "scores_auc = cross_val_score(logreg, X, y, cv=10, scoring='roc_auc')\n",
        "\n",
        "print('K-fold cross-validation results:')\n",
        "print(logreg.__class__.__name__+\" average accuracy is %2.3f\" % scores_accuracy.mean())\n",
        "print(logreg.__class__.__name__+\" average log_loss is %2.3f\" % -scores_log_loss.mean())\n",
        "print(logreg.__class__.__name__+\" average auc is %2.3f\" % scores_auc.mean())\n"
      ],
      "metadata": {
        "id": "chhEibXyDT-e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}